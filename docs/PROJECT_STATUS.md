# AltAnalyze2 SNAF Project Status & Results

*Last updated: August 25, 2025*

## üìä Project Overview

This document tracks the current progress, execution results, and cost analysis of the AltAnalyze2 SNAF workflows. Use this document to:

- Record Terra workflow execution costs and performance
- Calculate cost estimates for larger sample sets
- Track project milestones and future directions
- Document lessons learned and optimizations

---

## üöÄ Current Progress

### ‚úÖ Completed Milestones

- **Repository Setup**: Workflows, containers, and documentation complete
- **Container Development**: AltAnalyze and STAR aligner containers built and tested
- **Workflow Validation**: Both WDL workflows validate with womtool and miniwdl
- **Terra Integration**: Dockstore configuration complete for workflow discovery
- **GTEx Data Processing**: Scripts and validation tools for GTEx v10 dataset
- **Repository Health**: Comprehensive cleanup and hygiene improvements (Aug 2025)

### üîÑ In Progress

- [ ] **Terra CLI Testing**: Testing Terra's command-line interface for automated workflow execution
- [ ] **Platform Comparison**: Evaluating Terra vs SevenBridges vs AWS for cost efficiency and ease of management
- [ ] **Production GTEx Analysis**: Running splicing analysis on validated GTEx samples
- [ ] **Cost Optimization**: Analyzing resource usage and optimizing parameters
- [ ] **Performance Benchmarking**: Collecting execution time and resource metrics

---

## üí∞ Terra Execution Results & Cost Analysis

### Workflow Execution Summary

| Workflow | Date | Sample Count | Duration | Cost (USD) | Cost per Sample | Notes |
|----------|------|-------------|----------|------------|----------------|-------|
| `splicing_analysis` | 2025-08-XX | X | X hours | $X.XX | $X.XX/BAM | **Successful Terra GUI execution** |
| `star_alignment` | YYYY-MM-DD | X | X hours | $X.XX | $X.XX | Description |

*Update with actual Terra execution results - placeholder for Terra submission workflow URL*

**Recent Terra GUI Success**: Workflow successfully executed through Terra's web interface. Placeholder for Terra submission workflow URL to be added.

### Cost Breakdown Template

For each significant workflow run, document:

```markdown
## Run: [Workflow Name] - [Date]

**Configuration:**
- Sample count: X
- CPU cores: X
- Memory: X GB
- Disk: X GB (HDD/SSD)
- Runtime: X hours

**Costs:**
- Compute: $X.XX
- Storage: $X.XX
- Network: $X.XX
- **Total: $X.XX**

**Performance Notes:**
- [Any observations about performance, bottlenecks, or optimizations]

**Resource Utilization:**
- CPU utilization: X%
- Memory usage: X GB peak
- Disk I/O: [High/Medium/Low]
```

### Cost Estimation Model

#### Splicing Analysis (AltAnalyze)
Based on current execution data:

- **Small datasets** (1-10 samples): $X.XX per sample
- **Medium datasets** (10-50 samples): $X.XX per sample  
- **Large datasets** (50+ samples): $X.XX per sample

#### STAR Alignment
Based on current execution data:

- **Standard parameters**: $X.XX per sample
- **High-memory configuration**: $X.XX per sample

#### GTEx v10 Complete Analysis
- **Total validated samples**: 22,970
- **Estimated cost**: $X,XXX (based on X samples tested)
- **Estimated duration**: X days with Y concurrent workflows

---

## üóÑÔ∏è Datasets & Data Access

**See [DATASETS.md](./DATASETS.md) for comprehensive dataset inventory and processing status.**

### **Current Dataset Access Status**

#### GTEx v10 Dataset
- **Status**: ‚úÖ **Access Granted** via dbGaP and eRA Commons
- **Authorization**: Obtained through Nathan's institutional support
- **Validation**: 22,970/48,231 samples validated (47.6% success rate)
- **Location**: `data/gtex/` - comprehensive validation reports and sample organization
- **Processing**: Ready for large-scale analysis

#### TCGA Datasets  
- **TCGA-MESO**: ‚úÖ Available (~87 samples, pre-aligned BAMs)
- **TCGA-UVM**: ‚úÖ Available (sample inventory in progress)
- **Access**: Direct download from GDC Portal (no special authorization required)
- **Location**: `data/tcga/` - sample metadata and manifests prepared

#### CCHMC HPC Cluster
- **Status**: üîÑ **Institutional Access** - Local cluster resources
- **Data Location**: `/path/to/hpc/data/` - *Update with actual HPC data paths*
- **Processing**: Local high-performance computing environment
- **Advantages**: Direct institutional access, no cloud costs for compute
- **Data Types**: Various genomics datasets available locally

### **Future Data Sources (Resource Identification Needed)**

#### Proteomics Data
- **Status**: üîç **Resource Search Required**
- **Target**: Large-scale proteomics datasets for multi-omics integration
- **Platform**: Suitable for Terra cloud processing workflows
- **Priority**: Medium - for integrated genomics-proteomics analysis
- **Considerations**: File sizes, data formats, processing requirements

#### Single-cell RNA-seq Data  
- **Status**: üîç **Resource Search Required**
- **Target**: Large-scale single-cell datasets for method validation
- **Platform**: Terra cloud execution (high computational requirements)
- **Priority**: Medium - for cellular-level splicing analysis
- **Considerations**: Computational intensity, storage requirements, specialized workflows

#### Next Steps for Data Resource Discovery
- [ ] **Proteomics**: Identify suitable public datasets (ProteomeXchange, PRIDE, etc.)
- [ ] **Single-cell**: Evaluate 10X Genomics datasets, Human Cell Atlas, etc.  
- [ ] **CCHMC HPC**: Document available local datasets and access procedures
- [ ] **Integration Planning**: Design multi-omics analysis workflows

### **Platform Evaluation & CLI Testing**

#### Recent TODOs Completed
- [x] **Terra GUI Validation**: Successfully executed workflows via Terra web interface
- [ ] **Terra CLI Testing**: Validating command-line automation capabilities
- [ ] **Platform Cost Analysis**: Terra vs SevenBridges vs AWS comparison

#### Platform Comparison Criteria
| Platform | Ease of Use | Automation | Cost Efficiency | Status |
|----------|-------------|------------|----------------|--------|
| Terra | ‚úÖ GUI Validated | üîÑ CLI Testing | TBD | Primary candidate |
| SevenBridges | TBD | TBD | TBD | Under evaluation |
| AWS Batch | TBD | TBD | TBD | Future consideration |

### **Project Management & Collaboration**

**Google Document**: [Project Tasks Overview] - *Add link to collaborative project management document*

---

## üéØ Future Directions

### Short-term Goals (Next 1-3 months)

- [ ] **Platform Decision**: Complete Terra vs SevenBridges vs AWS evaluation
  - [ ] Finalize Terra CLI automation testing  
  - [ ] Compare total cost of ownership across platforms
  - [ ] Evaluate management overhead and learning curve
- [ ] **Complete GTEx Pilot**: Run splicing analysis on representative tissue samples
  - [ ] Target: Adipose Tissue (~1,300 validated samples) for cost baseline
  - [ ] Document actual Terra execution costs and performance
- [ ] **Cost Optimization**: 
  - [ ] Test HDD vs SSD performance impact
  - [ ] Optimize memory allocations based on GTEx pilot results
  - [ ] Evaluate preemptible instances for batch processing
- [ ] **TCGA Integration**: Expand to TCGA dataset processing
  - [ ] TCGA-MESO analysis (~87 samples)
  - [ ] Cross-platform compatibility validation
- [ ] **Data Resource Discovery**: Identify additional data sources
  - [ ] Proteomics datasets suitable for multi-omics integration
  - [ ] Single-cell RNA-seq datasets for Terra processing
  - [ ] Document CCHMC HPC cluster data access and available datasets

### Medium-term Goals (3-6 months)

- [ ] **Automated Processing Pipeline**: 
  - [ ] Implement chosen platform's CLI for batch processing
  - [ ] Develop cost monitoring and alerting system
  - [ ] Create automated quality control pipeline
- [ ] **Large-scale GTEx Analysis**: Process all 22,970 validated samples
- [ ] **Results Storage Strategy**: Efficient long-term storage of outputs
- [ ] **Cross-dataset Analysis**: Compare splicing patterns between GTEx and TCGA
- [ ] **Multi-omics Integration**: Incorporate proteomics and single-cell data
  - [ ] Develop proteomics-transcriptomics correlation workflows
  - [ ] Single-cell splicing analysis pipeline development
  - [ ] CCHMC HPC integration for local high-performance computing

### Long-term Goals (6+ months)

- [ ] **Multi-tissue Comparison**: Cross-tissue splicing analysis
- [ ] **Publication Pipeline**: Automated figure and table generation
- [ ] **External Dataset Integration**: Beyond GTEx and TCGA
- [ ] **Cloud Cost Optimization**: Advanced resource management

---

## üìà Performance Metrics & Benchmarks

### Execution Performance

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| BAM to BED conversion | < 1 hour/sample | X min | ‚úÖ/‚ùå |
| Junction analysis | < 2 hours/sample | X min | ‚úÖ/‚ùå |
| Memory efficiency | < 16 GB/sample | X GB | ‚úÖ/‚ùå |
| Disk utilization | < 50 GB temp | X GB | ‚úÖ/‚ùå |

### Cost Efficiency Targets

- **Target**: < $5.00 per sample for splicing analysis
- **Current**: $X.XX per sample
- **Status**: ‚úÖ Met / ‚ùå Above target / üîÑ Testing

---

## üîß Optimization Notes

### Resource Configuration Lessons

Document findings from different resource configurations:

#### Memory Allocation
- **16 GB**: Sufficient for samples < X GB
- **32 GB**: Required for samples X-Y GB
- **64+ GB**: Needed for samples > Y GB

#### Disk Configuration  
- **HDD**: Cost-effective for I/O light tasks, X% slower
- **SSD**: Required for I/O heavy tasks, X% performance improvement

#### CPU Scaling
- **Single core**: Baseline performance
- **4 cores**: X% improvement for parallel tasks
- **8+ cores**: Diminishing returns beyond X samples

### Cost Optimization Strategies

1. **Resource Right-sizing**: Match resources to sample characteristics
2. **Preemptible Instances**: Use for fault-tolerant batch jobs
3. **Storage Optimization**: Minimize intermediate file retention
4. **Batch Processing**: Combine small samples to improve efficiency

---

## üìã Execution Checklist

Before running large-scale analyses:

### Pre-execution
- [ ] Validate sample inputs with `validate_and_filter_inputs.py`
- [ ] Estimate costs using current metrics
- [ ] Confirm Terra billing account limits
- [ ] Set up monitoring and alerting

### During execution
- [ ] Monitor workflow progress in Terra
- [ ] Check resource utilization periodically
- [ ] Document any failures or issues

### Post-execution
- [ ] Record actual costs and performance metrics
- [ ] Update cost estimation model
- [ ] Archive results and clean up temporary files
- [ ] Update this document with findings

---

## üéØ Next Steps

*Update this section with immediate action items*

1. **Execute pilot run**: Run splicing analysis on [X tissue, Y samples]
2. **Document costs**: Record actual Terra execution costs
3. **Update estimates**: Refine cost model based on real data
4. **Plan next phase**: Determine optimal batch size and resource configuration

---

## üìû Contact & Resources

- **Repository**: [Current repository URL]
- **Terra Workspace**: [Your Terra workspace URL]
- **Dockstore**: [Workflow URLs]
- **Documentation**: See `docs/README.md` for complete documentation index

---

## üìù Change Log

| Date | Change | Author |
|------|--------|--------|
| 2025-08-25 | Initial document created | Claude |
| YYYY-MM-DD | [Description of changes] | [Author] |
